# CS 7643 - Deep Learning Final Project: Deep Learning for Waste Classification and Recycling

## Description
With the increasing emphasis on sustainability and waste management, automating the classification of waste materials plays a crucial role in improving recycling efficiency. This project aims to develop a deep learning model capable of automatically identifying various types of waste, such as paper, plastic, metal, glass, and cardboard, from image data. The project will leverage a pre-existing dataset, containing labeled images of different types of waste. The goal is to explore various deep learning architectures, including custom CNNs and transfer learning techniques, to achieve a high level of accuracy in waste classification and object detection. This project could have far-reaching applications in waste management systems, landfill monitoring, and environmental education.

## üèõ Repository Structure

```
DEEPLEARNING_PROJECT
‚îú‚îÄ‚îÄ data/                            --> Raw and processed data
‚îÇ   ‚îú‚îÄ‚îÄ raw/
‚îÇ   ‚îî‚îÄ‚îÄ processed/
‚îÇ
‚îú‚îÄ‚îÄ notebooks/                       --> Jupyter notebooks
‚îÇ   ‚îú‚îÄ‚îÄ exploration.ipynb            --> Dataset understanding and visualization
‚îÇ   ‚îî‚îÄ‚îÄ final_project.ipynb          --> Final executable notebook (calls src/main.py)
‚îÇ
‚îú‚îÄ‚îÄ src/                             --> Source code
‚îÇ   ‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ config_file.py           --> Project-level configuration (e.g., class names, device, paths)
‚îÇ   ‚îú‚îÄ‚îÄ evaluate/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ evaluate.py              --> Evaluation logic for trained models
‚îÇ   ‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ model_template.py        --> Model definition (e.g., CNN or custom architecture)
‚îÇ   ‚îú‚îÄ‚îÄ predict/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ predict.py               --> Inference on new data
‚îÇ   ‚îú‚îÄ‚îÄ preprocessing/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ helpers/
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ data_helpers.py      --> Preprocessing utilities (e.g., data split, augmentation)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ preprocessing.py         --> Data preparation workflow (transforms, loaders, etc.)
‚îÇ   ‚îú‚îÄ‚îÄ train/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ train.py                 --> Training logic (training loop, optimizer, loss)
‚îÇ   ‚îú‚îÄ‚îÄ utils/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ common.py                --> General utilities
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ logger.py                --> Logging configuration
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ plots.py                 --> Plotting functions for results or metrics
‚îÇ   ‚îî‚îÄ‚îÄ main.py                      --> Project orchestration: from preprocessing to training and evaluation
‚îÇ
‚îú‚îÄ‚îÄ outputs/                         --> Saved models, logs, predictions
‚îÇ   ‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îú‚îÄ‚îÄ logs/
‚îÇ   ‚îî‚îÄ‚îÄ results/
‚îÇ
‚îú‚îÄ‚îÄ requirements.txt                 --> Project dependencies
‚îú‚îÄ‚îÄ .gitignore                       --> Files and folders to ignore in git
‚îî‚îÄ‚îÄ README.md                        --> Project overview (this file)
```

## üöÄ How to run the project

### 1. Environment Setup

Create and activate a virtual environment (optional but recommended):

```bash
python -m venv .venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate
```

Install project dependencies:

```bash
pip install -r requirements.txt
```

### 2. Run the Final Notebook

All training, evaluation and analysis are integrated in the `final_project.ipynb` notebook.

Open it in Jupyter or VSCode and run each section interactively.


## ü§ù Contributing

To collaborate efficiently on this class project, we followed a simple and effective Git workflow using the `main` branch and feature branches:

1. We each created feature branches for specific tasks:
   ```bash
   git checkout -b feature/task_name
   ```

2. After completing our changes, we staged and committed them:
   ```bash
   git add .
   git commit -m "Describe your changes here"
   ```

3. We pushed our branches to the remote repository:
   ```bash
   git push origin feature/task_name
   ```

4. Pull Requests were created and reviewed by teammates before merging into `main`.

5. We regularly pulled the latest changes from `main` to stay updated:
   ```bash
   git pull origin main
   ```

This approach allowed us to work in parallel, avoid merge conflicts, and maintain a clean and organized project structure.

## üë• Team

- [Lourdes Artacho Sierras](mailto:lsierras3@gatech.edu)
- [Jorge Calvar Seco](mailto:jseco3@gatech.edu)
- [Carlota L√≥pez Argote](mailto:cargote3@gatech.edu)
